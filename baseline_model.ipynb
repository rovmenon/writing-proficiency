{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtwFhO1G1fgP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxMduM072Fca",
    "outputId": "3c14c23f-b669-4dea-9514-5e781b2490eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.15.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk spacy textstat scikit-learn\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lg8PSabn21E6",
    "outputId": "5d2b8f89-0d9d-41d0-9c21-23d72895056d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielskahill/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/danielskahill/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import textstat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load Spacy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define feature extraction functions\n",
    "def word_count(text):\n",
    "    return len(nltk.word_tokenize(text))\n",
    "\n",
    "def syllable_count(text):\n",
    "    return textstat.syllable_count(text)\n",
    "\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def complex_word_count(text):\n",
    "    return textstat.lexicon_count(text, removepunct=True) - textstat.difficult_words(text)\n",
    "\n",
    "def vocab_size(text):\n",
    "    return len(set(nltk.word_tokenize(text)))\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "def noun_chunks(text):\n",
    "    doc = nlp(text)\n",
    "    return len(list(doc.noun_chunks))\n",
    "\n",
    "def flesch_kincaid_score(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "def dale_chall_score(text):\n",
    "    return textstat.dale_chall_readability_score(text)\n",
    "\n",
    "def gunning_fog_index(text):\n",
    "    return textstat.gunning_fog(text)\n",
    "\n",
    "def coleman_liau_index(text):\n",
    "    return textstat.coleman_liau_index(text)\n",
    "\n",
    "def automated_readability_index(text):\n",
    "    return textstat.automated_readability_index(text)\n",
    "\n",
    "# create df with features\n",
    "def extract_features(df, text_column):\n",
    "    features = pd.DataFrame()\n",
    "    features['Word Count'] = df[text_column].progress_apply(word_count)\n",
    "    features['Syllable Count'] = df[text_column].progress_apply(syllable_count)\n",
    "    features['Character Count'] = df[text_column].progress_apply(character_count)\n",
    "    features['Complex Word Count'] = df[text_column].progress_apply(complex_word_count)\n",
    "    features['Vocab Size'] = df[text_column].progress_apply(vocab_size)\n",
    "    features['Lexical Diversity'] = df[text_column].progress_apply(lexical_diversity)\n",
    "    features['Noun Chunks'] = df[text_column].progress_apply(noun_chunks)\n",
    "    features['Flesch Kincaid Score'] = df[text_column].progress_apply(flesch_kincaid_score)\n",
    "    features['Dale Chall Score'] = df[text_column].progress_apply(dale_chall_score)\n",
    "    features['Gunning Fog Index'] = df[text_column].progress_apply(gunning_fog_index)\n",
    "    features['Coleman Liau Index'] = df[text_column].progress_apply(coleman_liau_index)\n",
    "    features['Automated Readability Index'] = df[text_column].progress_apply(automated_readability_index)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFCamDat 5 Class Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckg6YOXl29d8",
    "outputId": "f479f16f-72cd-4660-faf4-f99b2f242073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    149492\n",
      "2     85753\n",
      "3     55033\n",
      "4     22051\n",
      "5      4891\n",
      "Name: cefr_numeric, dtype: int64\n",
      "Int64Index([0, 1, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 317220/317220 [01:24<00:00, 3740.08it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:16<00:00, 18851.28it/s]\n",
      "100%|█████████████████████████████████████████████████| 317220/317220 [00:00<00:00, 1703157.83it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:16<00:00, 18960.61it/s]\n",
      "100%|████████████████████████████████████████████████████| 317220/317220 [01:25<00:00, 3727.21it/s]\n",
      "100%|████████████████████████████████████████████████████| 317220/317220 [01:24<00:00, 3733.68it/s]\n",
      "100%|█████████████████████████████████████████████████████| 317220/317220 [17:57<00:00, 294.29it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:21<00:00, 14682.84it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:22<00:00, 14398.97it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:22<00:00, 14223.08it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:13<00:00, 24192.77it/s]\n",
      "100%|███████████████████████████████████████████████████| 317220/317220 [00:10<00:00, 29627.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_imputed length: 253776, y_train length: 253776\n",
      "X_test_imputed length: 63444, y_test length: 63444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83     29923\n",
      "           1       0.62      0.49      0.54     17097\n",
      "           2       0.66      0.74      0.70     10984\n",
      "           3       0.64      0.54      0.59      4453\n",
      "           4       0.43      0.29      0.35       987\n",
      "\n",
      "    accuracy                           0.72     63444\n",
      "   macro avg       0.63      0.59      0.60     63444\n",
      "weighted avg       0.71      0.72      0.71     63444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielskahill/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'balanced_data' is your dataframe and 'text' is the column with text data\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "balanced_data = pd.read_csv('../efcamdat/efcamdat2.csv')\n",
    "\n",
    "#balanced_data = balanced_data.sample(n=15000, random_state=42)\n",
    "\n",
    "print(balanced_data['cefr_numeric'].value_counts())\n",
    "\n",
    "balanced_data['label'] = balanced_data['cefr_numeric'].apply(lambda x: x - 1)\n",
    "balanced_data['label'] = balanced_data['label'].astype('category')\n",
    "print(balanced_data['label'].cat.categories)\n",
    "\n",
    "features = extract_features(balanced_data, 'text')\n",
    "\n",
    "data_with_features = pd.concat([features, balanced_data['label'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop rows with missing values in the label column\n",
    "data_with_features = data_with_features.dropna(subset=['label'])\n",
    "\n",
    "X = data_with_features.drop(columns=['label'])\n",
    "y = data_with_features['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values using imputer for features only\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Verify the lengths of the training and testing sets\n",
    "print(f\"X_train_imputed length: {len(X_train_imputed)}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_test_imputed length: {len(X_test_imputed)}, y_test length: {len(y_test)}\")\n",
    "\n",
    "# Train logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log_reg.predict(X_test_imputed)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFCamDat 6 Class Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    100000\n",
      "2    100000\n",
      "1    100000\n",
      "4     61329\n",
      "5     14698\n",
      "6      1940\n",
      "Name: cefr_numeric, dtype: int64\n",
      "Int64Index([0, 1, 2, 3, 4, 5], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 377967/377967 [02:15<00:00, 2796.12it/s]\n",
      "100%|███████████████████████████████████████████████████| 377967/377967 [00:24<00:00, 15677.85it/s]\n",
      "100%|█████████████████████████████████████████████████| 377967/377967 [00:00<00:00, 1717315.08it/s]\n",
      "100%|███████████████████████████████████████████████████| 377967/377967 [00:31<00:00, 12048.48it/s]\n",
      "100%|████████████████████████████████████████████████████| 377967/377967 [02:16<00:00, 2771.34it/s]\n",
      "100%|████████████████████████████████████████████████████| 377967/377967 [02:16<00:00, 2769.93it/s]\n",
      "100%|█████████████████████████████████████████████████████| 377967/377967 [26:55<00:00, 233.92it/s]\n",
      "100%|███████████████████████████████████████████████████| 377967/377967 [00:35<00:00, 10555.46it/s]\n",
      "100%|████████████████████████████████████████████████████| 377967/377967 [00:40<00:00, 9308.81it/s]\n",
      "100%|████████████████████████████████████████████████████| 377967/377967 [00:40<00:00, 9290.81it/s]\n",
      "100%|███████████████████████████████████████████████████| 377967/377967 [00:20<00:00, 18783.04it/s]\n",
      "100%|███████████████████████████████████████████████████| 377967/377967 [00:17<00:00, 21637.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_imputed length: 302373, y_train length: 302373\n",
      "X_test_imputed length: 75594, y_test length: 75594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     19928\n",
      "           1       0.59      0.59      0.59     20008\n",
      "           2       0.59      0.68      0.63     20055\n",
      "           3       0.59      0.55      0.57     12308\n",
      "           4       0.44      0.17      0.24      2929\n",
      "           5       0.00      0.00      0.00       366\n",
      "\n",
      "    accuracy                           0.63     75594\n",
      "   macro avg       0.50      0.46      0.46     75594\n",
      "weighted avg       0.63      0.63      0.63     75594\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielskahill/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'balanced_data' is your dataframe and 'text' is the column with text data\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "balanced_data = pd.read_csv('../efcamdat_sub.csv')\n",
    "\n",
    "#balanced_data = balanced_data.sample(n=15000, random_state=42)\n",
    "\n",
    "print(balanced_data['cefr_numeric'].value_counts())\n",
    "\n",
    "balanced_data['label'] = balanced_data['cefr_numeric'].apply(lambda x: x - 1)\n",
    "balanced_data['label'] = balanced_data['label'].astype('category')\n",
    "print(balanced_data['label'].cat.categories)\n",
    "\n",
    "features = extract_features(balanced_data, 'text')\n",
    "\n",
    "data_with_features = pd.concat([features, balanced_data['label'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop rows with missing values in the label column\n",
    "data_with_features = data_with_features.dropna(subset=['label'])\n",
    "\n",
    "X = data_with_features.drop(columns=['label'])\n",
    "y = data_with_features['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values using imputer for features only\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Verify the lengths of the training and testing sets\n",
    "print(f\"X_train_imputed length: {len(X_train_imputed)}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_test_imputed length: {len(X_test_imputed)}, y_test length: {len(y_test)}\")\n",
    "\n",
    "# Train logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log_reg.predict(X_test_imputed)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yD-o_2kyly3"
   },
   "source": [
    "## OneStopEnglish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    2651\n",
      "2    2595\n",
      "1    2151\n",
      "Name: labels, dtype: int64\n",
      "Int64Index([1, 2, 3], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 7397/7397 [00:01<00:00, 5228.13it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 15713.02it/s]\n",
      "100%|█████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 1682406.96it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 15675.66it/s]\n",
      "100%|████████████████████████████████████████████████████████| 7397/7397 [00:01<00:00, 5774.22it/s]\n",
      "100%|████████████████████████████████████████████████████████| 7397/7397 [00:01<00:00, 5821.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 7397/7397 [00:21<00:00, 336.26it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 15885.01it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 13099.43it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 13196.51it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 28931.60it/s]\n",
      "100%|███████████████████████████████████████████████████████| 7397/7397 [00:00<00:00, 34165.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_imputed length: 5917, y_train length: 5917\n",
      "X_test_imputed length: 1480, y_test length: 1480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       429\n",
      "           2       0.54      0.52      0.53       547\n",
      "           3       0.55      0.57      0.56       504\n",
      "\n",
      "    accuracy                           0.53      1480\n",
      "   macro avg       0.53      0.53      0.53      1480\n",
      "weighted avg       0.53      0.53      0.53      1480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielskahill/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'balanced_data' is your dataframe and 'text' is the column with text data\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "balanced_data = pd.read_csv('../onestopec.csv')\n",
    "\n",
    "#balanced_data = balanced_data.sample(n=15000, random_state=42)\n",
    "\n",
    "print(balanced_data['labels'].value_counts())\n",
    "\n",
    "balanced_data['label'] = balanced_data['labels'].apply(lambda x: x - 1)\n",
    "balanced_data['label'] = balanced_data['labels'].astype('category')\n",
    "print(balanced_data['label'].cat.categories)\n",
    "balanced_data['text'] = balanced_data['text'].apply(lambda x: str(x))\n",
    "\n",
    "features = extract_features(balanced_data, 'text')\n",
    "\n",
    "data_with_features = pd.concat([features, balanced_data['label'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop rows with missing values in the label column\n",
    "data_with_features = data_with_features.dropna(subset=['label'])\n",
    "\n",
    "X = data_with_features.drop(columns=['label'])\n",
    "y = data_with_features['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values using imputer for features only\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Verify the lengths of the training and testing sets\n",
    "print(f\"X_train_imputed length: {len(X_train_imputed)}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_test_imputed length: {len(X_test_imputed)}, y_test length: {len(y_test)}\")\n",
    "\n",
    "# Train logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log_reg.predict(X_test_imputed)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
