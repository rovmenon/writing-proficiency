{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4726aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e223850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel, BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57047113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../efcamdat_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a567af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text'].to_numpy()\n",
    "true_labels = df['cefr_numeric'].apply(lambda x: int(x) - 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75c59f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  METAL, no compute capability (probably not an Nvidia GPU)\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:33:30.838014: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-25 18:33:30.838166: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "bert_model = tf.keras.models.load_model('../models/bert_model_final.keras', {'TFBertModel': TFBertModel})\n",
    "roberta_cl_model = tf.keras.models.load_model('../models/roberta_model_final.keras', {'TFRobertaModel': TFRobertaModel})\n",
    "#roberta_gru_model = tf.keras.models.load_model('../models/roberta_gru_model.keras', {'TFRobertaModel': TFRobertaModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77b25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 85\n",
    "\n",
    "bert_tokens = bert_tokenizer([str(x) for x in texts], truncation=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, return_tensors='tf')\n",
    "roberta_tokens = roberta_tokenizer([str(x) for x in texts], truncation=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa64022",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': bert_tokens['input_ids'],\n",
    "            'token_type_ids': bert_tokens['token_type_ids'],\n",
    "            'attention_mask': bert_tokens['attention_mask']\n",
    "        },\n",
    "        true_labels\n",
    "    ))\n",
    "\n",
    "roberta_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids_layer': roberta_tokens['input_ids'],\n",
    "            'attention_mask_layer': roberta_tokens['attention_mask']\n",
    "        },\n",
    "        true_labels\n",
    "    ))\n",
    "\n",
    "bert_dataset = bert_dataset.batch(32)\n",
    "roberta_dataset = roberta_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cbf7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:34:15.707899: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-25 18:34:15.709809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097/1097 [==============================] - 309s 280ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:39:25.568760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1097 [..............................] - ETA: 1:09:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:39:28.430644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097/1097 [==============================] - 315s 284ms/step\n"
     ]
    }
   ],
   "source": [
    "bert_preds = bert_model.predict(bert_dataset)\n",
    "roberta_cl_preds = roberta_cl_model.predict(roberta_dataset)\n",
    "#roberta_gru_preds = roberta_gru_model.predict(roberta_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f07cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preds = np.argmax(bert_preds, axis=-1)\n",
    "roberta_cl_preds = np.argmax(roberta_cl_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71310c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_wrong_ind = np.where(bert_preds != true_labels)\n",
    "rob_wrong_ind = np.where(roberta_cl_preds != true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ea8e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT has 848 wrong predictions\n",
      "RoBERTa has 1133 wrong predictions\n"
     ]
    }
   ],
   "source": [
    "bert_wrong_texts = texts[bert_wrong_ind]\n",
    "rob_wrong_texts = texts[rob_wrong_ind]\n",
    "\n",
    "print(f\"BERT has {len(bert_wrong_texts)} wrong predictions\")\n",
    "print(f\"RoBERTa has {len(rob_wrong_texts)} wrong predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c50c4",
   "metadata": {},
   "source": [
    "## Exploring Texts that Both Got Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "123d434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 427 predictions that both got wrong\n"
     ]
    }
   ],
   "source": [
    "both_wrong = np.intersect1d(rob_wrong_ind, bert_wrong_ind)\n",
    "print(f\"There are {len(both_wrong)} predictions that both got wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fefddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  24],\n",
       "       [  1,  65],\n",
       "       [  2, 156],\n",
       "       [  3,  66],\n",
       "       [  4, 116]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value counts of the labels they got wrong the most \n",
    "np.asarray(np.unique(true_labels[both_wrong], return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b5551463",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_only_wrong = [i for i in texts[bert_wrong_ind] if i not in texts[rob_wrong_ind]]\n",
    "rob_only_wrong = [i for i in texts[rob_wrong_ind] if i not in texts[bert_wrong_ind]]\n",
    "bert_only_wrongid = [i for i in bert_wrong_ind[0] if i not in rob_wrong_ind[0]]\n",
    "rob_only_wrongid = [i for i in rob_wrong_ind[0] if i not in bert_wrong_ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7696851c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_only_wrongid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e0d518f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rob_only_wrongid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "244a6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_both_wrongs(class_n, who='both', verbose=True):\n",
    "    if who == 'both':\n",
    "        idxs = np.intersect1d(np.where(true_labels == class_n), both_wrong)\n",
    "        idx = np.random.choice(idxs)\n",
    "    elif who == 'bert':\n",
    "        idxs = np.intersect1d(np.where(true_labels == class_n), bert_only_wrongid)\n",
    "        idx = np.random.choice(idxs)\n",
    "    else:\n",
    "        idxs = np.intersect1d(np.where(true_labels == class_n), rob_only_wrongid)\n",
    "        idx = np.random.choice(idxs)\n",
    "    if verbose:\n",
    "        print(\"BERT predicted label: \", bert_preds[idx])\n",
    "        print(\"RoBERTa predicted label: \", roberta_cl_preds[idx])\n",
    "        print(\"Actual label: \", true_labels[idx])\n",
    "    return bert_preds[idx], roberta_cl_preds[idx], true_labels[idx], texts[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ac700",
   "metadata": {},
   "source": [
    "### Sample from A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fcc0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  1\n",
      "RoBERTa predicted label:  1\n",
      "Actual label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  My name is Evelyne and I am retired of the work about since months ago. Now I get up at 8 for looking my harder and the birds. I go walking my my pretty dog, Twiny. It's my beloved dog ! So I like gardening and i go walking  2 afernoon in the week with a club. Also I like take photo and my hobby is scrapbooking.\\n\\t\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d870fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  1\n",
      "Actual label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Hi! I don't really care about what everyone likes or don't likes. I'm a passionate cook so you better like it. Everything will tastes delicious. I guess you will agree with me. I hope all off you are free and I'm looking forward to meeting you next Friday. See you.\\n\\t\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec39480",
   "metadata": {},
   "source": [
    "### Sample from A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fc86c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  3\n",
      "RoBERTa predicted label:  3\n",
      "Actual label:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Dear Polaris,   buy a good book about history which has more than two thousands sides. You should need some weeks to go through it. After that you will forget all the scrap you were looking for. Believe me, after a good book about history there will remain only one whish: a time machine. But you won't find a shop on this entire planet where you could buy such a machine. Kind Regards,  Tom\\n\\t\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a01fd2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  -Welcome to Domenici's Family Blog- In this Blog you will found some resume about the members of my family and what each like to do and eat or drink. Danilo Domenicis (It's Me) We can say that's Danilo is a kind of person that like to workout and he works very much! He is 21 yo and works with IT. He loves to eat Pizza but cause he likes also to workout is normally to see him eating just chicken and potatoe. Silvana Domenicis (Danilo's Mother) Silvana is a good person that work a lot to keep all the bills and organization in Domenici's house. She loves to eat pasta and she normally likes to go to the movie.\\n\\t\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc937a",
   "metadata": {},
   "source": [
    "### Sample from B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8dc4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  3\n",
      "RoBERTa predicted label:  3\n",
      "Actual label:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  The art of deal unfortunately I don't have for purchase,  but I always make negotiation in my personal life, for example what movie we'll watch, places to visit and dates to do all these. I almost never negotiate any purchase, It is work for my father, he is a master in negotiations! I can't because sellers have strategies that I can't escape, so I buy by pressure and no discount! However I have learned negotiations and now I am firmer to buy anything. I've already worked in negotiations, when I was eighteen to nineteen years old, It was for a banking and I had great argumentations, counteroffer and solutions to offer for the costumer. I could to explore the reason of dissatisfaction with the bank and I started to negotiation with them.\\n\\t\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52a76419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  3\n",
      "RoBERTa predicted label:  3\n",
      "Actual label:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Good manners in my country Brazil is a beautiful country visited by millions of people. Here are some basic rules of etiquettes when you're eating at a restaurant or in a home's friend: Firstly, you're supposed to put the napkin on his lap. Do not put your elbows on the table. Chew food with mouth closed and slouly. Do not overfull the fork or spoon. Do not blow the soup to cool. Do not slurping when drinking liquids or soups. Do not smoke in prohibited places. Avoid talking with your mouth full of food. As others countries, You're expected do not spitting in the streets. Staring and pointing someone are considered offensive.\\n\\t\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df16831",
   "metadata": {},
   "source": [
    "### Sample from B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25c75478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Hello Tom. Do you remember that old friend from claim her about the hug she gave me moments ago. I don't know what to do, you know she isn't my girlfriend but how to explain besides I couldn't say a word maybe it was the impression, I didn't know, but what an awkward situation.\\n\\t\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18c03628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  I think that the internet really change the world.For instance,if we would like to go somewhere We've never been to,we should confirm how to get there by searching a map before the launch of the internet.We can easily search anything we want to know by using the internet.But using the internet is the double-edged sword indeed.The internet always gives us a lot of information,so we tend to use the information in a casual way rather than tend to think by ourselves.For instance,there were large social problems that many Japanese college students submit their graduation thesis whose conclusions are gathered by the internet.The internet can enlarge our vision but may deprive us of thoughtfulness and originality.We have to know its benefit and deficit,then we have to make good use of it,I think.\\n\\t\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743bdb15",
   "metadata": {},
   "source": [
    "### Sample from C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "493fd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  People's lives will be much easier in 20 years thanks to technical improvement.  Retinal scanning will facilitate the identification process. No passports, no visas, no administrative procedures will warrantee a comfortable life.  Artificial intelligence will be in the run to replace people in some positions like tourist guide, receptionist, assistant, security guard...There are certainly less jobs, but living conditions will be much better.  People can work at home or anywhere as they wish through Internet and telebeaming. With the help of satellite cellphones, communication will be thus far effective. Transport will be different, flying trains, high speed bus which are hydropowered are public transport means. There will be no cars which use fuel. The pollution will consequently diminished. Houses will be built ecofriendly, with more green space and lightened by solar-powered bulbs. Waste will be obligated to be reused or recycled. Plastic material will be highly taxed and banned in many countries. Children will have more time doing extra-curricular activities and will be educated to protect our natural environment. \\n\\t\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6fe8d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  I'd like to show what are similar or different between Japanese and Hawaiian elementary schools. Because I grew up in Hawaii and went back to Japan when I was 15 years old. The first different thing is teachers. In Japan, a teacher has his/her classroom and teaches all subjects. Students study in the same classroom without going to other rooms. A teacher comes in and goes to the teacher's office after a class. Teachers need to prepare many things and have several skills. On the other hand, students go to each room to take a class in Hawaii. They have English, math, science, PE's teachers and others. Teachers are experts. Each teacher has the ability to teach the subject deeply. The second different thing is how students study subjects in school. In Japan, classes are teacher-oriented. Teachers have an answer and students have to meet it. Otherwise, students fail. There are a lot of time to get information from teachers but less time to practice. On the other hand, classes are student-oriented in Hawaii. Students need to find an answer on their ways. It's more difficult than Japanese way. I prefer Hawaiian education system.\\n\\t\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99440103",
   "metadata": {},
   "source": [
    "## Exploring BERT Wrong but RoBERTa Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf50f61",
   "metadata": {},
   "source": [
    "### A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bdf898c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  1\n",
      "RoBERTa predicted label:  0\n",
      "Actual label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Hi! I'm having a birthday party on sunday. I invite you can go on. In the party, We can meet many friends. In the morning , We can watch TV. In the afternoon, We have a lunch in my house. I can make much delicious food, I think you must like it. Hope you go on.  Johnson\\n\\t\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(0, 'bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e89d1",
   "metadata": {},
   "source": [
    "### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05efd8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  1\n",
      "Actual label:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\t  To All staff members.   This office has received many complaints from clients concerning the lack of professional dress in our offices. four example, today I noticed men wearing baggy trousers, basebal caps, and polyester shirts. This reflects poorly on our company and is not the trend for a company dealing with bankers and stock brokers.   We want you to wear stylish clothes, but we do not want to see our staff following trends of teenagers and gang members.  \\n\\t'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(1, 'bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1a67c",
   "metadata": {},
   "source": [
    "### B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f3226efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  1\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\t  At first I met my husband in elementary school. He was in class two and I in class one. He was very tall and he had a terrible suitcase instead of a satchel.  A few years later I was sixteen years old, I went to the bowling with my friends.  We went there with motorbike. One of my friends brought his best friend. He brought me home at 23 oclock with his motorbike. It was winter and it was very cold. But we stood at the door and talked all night. When it was five oclock in the Morning, we realized that are invited to the same party today. He brought me home again and we talked all night. He was very shy, but now I took all my courage and kissed him. This was the beginning of our relationship.\\n\\t'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(2, 'bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356b807",
   "metadata": {},
   "source": [
    "### B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "908925d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  4\n",
      "RoBERTa predicted label:  3\n",
      "Actual label:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Although working together for so many years, it still startles me how Nelson begins each and every day: always reinvigorated and prompt for any possible challenges he will face. Nelson is, as a rule, an affable and approachable guy. Nevertheless, any subtle constructive criticism devastates him. Let's face it: we can't always walk on egg shells around him if we want the work team to accomplish its demanding goals. Nelson excels at communicating difficult concepts to grasp by most of us in easy to understand daily language. His communication skills have skyrocketed in the last three years. He is undoubtedly a creative and competent guy but has a conspicuous tendency to act before thinking, therefore, failing to create new solutions. Nelson is a loyal and trustworthy employee, who always gets the job perfectly done and whose general performance is above expectations.\\n\\t\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(3, 'bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5fd7d",
   "metadata": {},
   "source": [
    "### C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d756468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  1\n",
      "RoBERTa predicted label:  4\n",
      "Actual label:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  The best website where to buy on in Italy is Mondatori.it.. I am custom to spend a lot of money there. Is very simple and easy to use. Is rich on information and the customer service is at your disposal 24/7. A vast amount of customers are online and they exchange information using a chat pod. The secret of this website? The more you spend the more discount you'll have on your next purchasing. This is due to the large quantity of goods that they possess and in this way they are much more competitive than a small shop in town. I always decide to buy more than one article and reach 250 euro as total amount. In this way, the shipping taxes are free. What do I buy on Mondadori.it? You can find anything you want. Starting from music, books, clothes and IT devices. As I said, everything is online, and the price is unbelievably favorable. There is also a vacation section that permits you to dream about your next vacation, and the reason why a lot of us decide to buy there instead of travel agency is the functionality of this website. The software program always work, and I have had never made a complaint.%%\\n\\t\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(4, 'bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c0ddc",
   "metadata": {},
   "source": [
    "## Exploring RoBERTa Wrong but BERT Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf7108",
   "metadata": {},
   "source": [
    "### A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e391784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  0\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\t  Hi, Ed. Let me thing... I have 10 dollars too. Meaby we can buy special pens, I remember saw some one in the mall, those pens have a special form, its for a better writing. Well, tell me if you are agre. Sosa.\\n\\t'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(0,'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a582e",
   "metadata": {},
   "source": [
    "### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3806f924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  1\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\t  Dear, mrs. I am looking for a job, so my experience it not much, after I work the waitres but i need more money. but I studiend now at the university so i see you need help marketing assitant. maybe if you need any call me. ok thanks you sinceraly Emilio\\n\\t'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(1, 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23401953",
   "metadata": {},
   "source": [
    "### B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5df562e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  2\n",
      "RoBERTa predicted label:  3\n",
      "Actual label:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Two moth ago I bougth my first tablet, before I had bougth I did not like of idea of have a tablet becase I didn't see useful for this. But today I am very happy with my new mobile gadget. It goes with me in all places and I can access the internet conection in everwhere. This tablet make me more productive and also I can talk with my friends and family. Other thing important is the games, I can buy many kinds of games and it is an excelent thing for make when I don't have anything for to make. An thing that I use much is the calendar on tablet, it help me to remenber my mettings and my tasks.\\n\\t\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(2, 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef072e",
   "metadata": {},
   "source": [
    "### B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f5541f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  3\n",
      "RoBERTa predicted label:  4\n",
      "Actual label:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\t  Dear colleagues,  as project manager I want to give you a comprehensive induction to our new and challengening project which will start next month. On the next page you can inform you about all the details of this project as well as terms and conditons.  But first of all I propose some importants aspects of our corporate management strategy which is absolutely necessary in order to process all tasks successfully. Every second day in the week we will have a meeting about one hour. The most important issue in these meetings is communcation. Please notice, before embarking on a strategy we initiate a brainstorming which should help all project members and make the goals of our team clear and incisive.  Moreover, everyone should be prepared and report about problems and challenges of current tasks. Please remember to turn off mobile phones and any other potential disturbances.  In conclusion you have to know that the project should be finished within three months. Our customer is focused on social aspects and sustaining developments. It will be a difficult challenge but I am convinced to reach all goals in the most effective way.\\n\\t'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(3, 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4526c",
   "metadata": {},
   "source": [
    "### C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2da10186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predicted label:  4\n",
      "RoBERTa predicted label:  2\n",
      "Actual label:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\t  Dear Mr Freeman, I want you to know that we are working hard to fulfil your order before the scheduled date. However, I want to be sure about the color we will be using.  So, I'm sending you some samples for your apreciation. Please let me known which one you prefer. I need to receive your feedback by October 21. I also would like to invite you to visit our factory on the first week of November, when you could see our progress and we could discuss the packaging options. Please let me know if you agree with that and what is the date that suits you most. Best regards, Lucila\\n\\t\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_both_wrongs(4, 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240b149",
   "metadata": {},
   "source": [
    "## Seeing if we can explain why certain texts were wrong for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "efef8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielskahill/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/danielskahill/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Code from baseline model metrics \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import textstat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load Spacy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define feature extraction functions\n",
    "def word_count(text):\n",
    "    return len(nltk.word_tokenize(text))\n",
    "\n",
    "def syllable_count(text):\n",
    "    return textstat.syllable_count(text)\n",
    "\n",
    "def character_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def complex_word_count(text):\n",
    "    return textstat.lexicon_count(text, removepunct=True) - textstat.difficult_words(text)\n",
    "\n",
    "def vocab_size(text):\n",
    "    return len(set(nltk.word_tokenize(text)))\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "def noun_chunks(text):\n",
    "    doc = nlp(text)\n",
    "    return len(list(doc.noun_chunks))\n",
    "\n",
    "def flesch_kincaid_score(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "def dale_chall_score(text):\n",
    "    return textstat.dale_chall_readability_score(text)\n",
    "\n",
    "def gunning_fog_index(text):\n",
    "    return textstat.gunning_fog(text)\n",
    "\n",
    "def coleman_liau_index(text):\n",
    "    return textstat.coleman_liau_index(text)\n",
    "\n",
    "def automated_readability_index(text):\n",
    "    return textstat.automated_readability_index(text)\n",
    "\n",
    "# create df with features\n",
    "def extract_features(df, text_column):\n",
    "    features = pd.DataFrame()\n",
    "    features['Word Count'] = df[text_column].apply(word_count)\n",
    "    features['Syllable Count'] = df[text_column].apply(syllable_count)\n",
    "    features['Character Count'] = df[text_column].apply(character_count)\n",
    "    features['Complex Word Count'] = df[text_column].apply(complex_word_count)\n",
    "    features['Vocab Size'] = df[text_column].apply(vocab_size)\n",
    "    features['Lexical Diversity'] = df[text_column].apply(lexical_diversity)\n",
    "    features['Noun Chunks'] = df[text_column].apply(noun_chunks)\n",
    "    features['Flesch Kincaid Score'] = df[text_column].apply(flesch_kincaid_score)\n",
    "    features['Dale Chall Score'] = df[text_column].apply(dale_chall_score)\n",
    "    features['Gunning Fog Index'] = df[text_column].apply(gunning_fog_index)\n",
    "    features['Coleman Liau Index'] = df[text_column].apply(coleman_liau_index)\n",
    "    features['Automated Readability Index'] = df[text_column].apply(automated_readability_index)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cf4ea95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wrong_metrics_df(model):\n",
    "    classes = [0, 1, 2, 3, 4]\n",
    "    df = pd.DataFrame(columns=['bert_pred', 'roberta_pred', 'true', 'text'])\n",
    "    for c in classes:\n",
    "        for i in range(24):\n",
    "            b, r, t, text = sample_both_wrongs(c, model, verbose=False)\n",
    "            temp = pd.DataFrame({'bert_pred': [b], 'roberta_pred': [r], 'true': [t], 'text': [text]})\n",
    "            df = pd.concat([df, temp])\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    features = extract_features(df, 'text')\n",
    "    features = features.reset_index()\n",
    "    merged = pd.merge(df, features, left_index=True, right_index=True)\n",
    "    features['label'] = merged['true']\n",
    "    return merged, features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0db0f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_df, roberta_features = generate_wrong_metrics_df('roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "31191339",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df, bert_features = generate_wrong_metrics_df('bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b5b3bff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable Count</th>\n",
       "      <th>Character Count</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Vocab Size</th>\n",
       "      <th>Lexical Diversity</th>\n",
       "      <th>Noun Chunks</th>\n",
       "      <th>Flesch Kincaid Score</th>\n",
       "      <th>Dale Chall Score</th>\n",
       "      <th>Gunning Fog Index</th>\n",
       "      <th>Coleman Liau Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.5</td>\n",
       "      <td>67.208333</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>293.458333</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>47.291667</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>4.591667</td>\n",
       "      <td>8.258750</td>\n",
       "      <td>6.705833</td>\n",
       "      <td>5.340417</td>\n",
       "      <td>5.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.5</td>\n",
       "      <td>78.041667</td>\n",
       "      <td>85.291667</td>\n",
       "      <td>350.750000</td>\n",
       "      <td>58.416667</td>\n",
       "      <td>52.916667</td>\n",
       "      <td>0.688758</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.908333</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>6.512917</td>\n",
       "      <td>5.194583</td>\n",
       "      <td>5.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.5</td>\n",
       "      <td>132.458333</td>\n",
       "      <td>158.333333</td>\n",
       "      <td>638.333333</td>\n",
       "      <td>98.833333</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>0.653122</td>\n",
       "      <td>33.625000</td>\n",
       "      <td>8.141667</td>\n",
       "      <td>8.101667</td>\n",
       "      <td>10.252917</td>\n",
       "      <td>7.347500</td>\n",
       "      <td>9.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.5</td>\n",
       "      <td>164.166667</td>\n",
       "      <td>203.583333</td>\n",
       "      <td>810.375000</td>\n",
       "      <td>126.333333</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>45.041667</td>\n",
       "      <td>8.258333</td>\n",
       "      <td>7.544167</td>\n",
       "      <td>10.253333</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>9.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.5</td>\n",
       "      <td>185.125000</td>\n",
       "      <td>229.916667</td>\n",
       "      <td>915.625000</td>\n",
       "      <td>139.083333</td>\n",
       "      <td>108.750000</td>\n",
       "      <td>0.591990</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>8.037500</td>\n",
       "      <td>7.929583</td>\n",
       "      <td>10.106667</td>\n",
       "      <td>8.121250</td>\n",
       "      <td>9.162500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Word Count  Syllable Count  Character Count  Complex Word Count  \\\n",
       "label                                                                           \n",
       "0       11.5   67.208333       68.833333       293.458333           46.666667   \n",
       "1       35.5   78.041667       85.291667       350.750000           58.416667   \n",
       "2       59.5  132.458333      158.333333       638.333333           98.833333   \n",
       "3       83.5  164.166667      203.583333       810.375000          126.333333   \n",
       "4      107.5  185.125000      229.916667       915.625000          139.083333   \n",
       "\n",
       "       Vocab Size  Lexical Diversity  Noun Chunks  Flesch Kincaid Score  \\\n",
       "label                                                                     \n",
       "0       47.291667           0.710995    18.416667              4.591667   \n",
       "1       52.916667           0.688758    22.000000              4.908333   \n",
       "2       85.833333           0.653122    33.625000              8.141667   \n",
       "3       95.333333           0.585100    45.041667              8.258333   \n",
       "4      108.750000           0.591990    47.333333              8.037500   \n",
       "\n",
       "       Dale Chall Score  Gunning Fog Index  Coleman Liau Index  \\\n",
       "label                                                            \n",
       "0              8.258750           6.705833            5.340417   \n",
       "1              7.410000           6.512917            5.194583   \n",
       "2              8.101667          10.252917            7.347500   \n",
       "3              7.544167          10.253333            7.490000   \n",
       "4              7.929583          10.106667            8.121250   \n",
       "\n",
       "       Automated Readability Index  \n",
       "label                               \n",
       "0                         5.604167  \n",
       "1                         5.133333  \n",
       "2                         9.358333  \n",
       "3                         9.291667  \n",
       "4                         9.162500  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob_wrong_stats = roberta_features.groupby('label').agg('mean')\n",
    "rob_wrong_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bc9f21fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable Count</th>\n",
       "      <th>Character Count</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Vocab Size</th>\n",
       "      <th>Lexical Diversity</th>\n",
       "      <th>Noun Chunks</th>\n",
       "      <th>Flesch Kincaid Score</th>\n",
       "      <th>Dale Chall Score</th>\n",
       "      <th>Gunning Fog Index</th>\n",
       "      <th>Coleman Liau Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.5</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>57.541667</td>\n",
       "      <td>243.166667</td>\n",
       "      <td>42.833333</td>\n",
       "      <td>37.958333</td>\n",
       "      <td>0.687275</td>\n",
       "      <td>15.541667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>6.295417</td>\n",
       "      <td>4.695000</td>\n",
       "      <td>3.884583</td>\n",
       "      <td>3.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.5</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>361.458333</td>\n",
       "      <td>51.375000</td>\n",
       "      <td>51.458333</td>\n",
       "      <td>0.685836</td>\n",
       "      <td>20.291667</td>\n",
       "      <td>7.591667</td>\n",
       "      <td>8.812917</td>\n",
       "      <td>9.763750</td>\n",
       "      <td>7.345000</td>\n",
       "      <td>8.570833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.5</td>\n",
       "      <td>106.791667</td>\n",
       "      <td>118.833333</td>\n",
       "      <td>498.208333</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>70.208333</td>\n",
       "      <td>0.658725</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>5.229167</td>\n",
       "      <td>7.376667</td>\n",
       "      <td>7.239583</td>\n",
       "      <td>6.082083</td>\n",
       "      <td>6.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.5</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>183.416667</td>\n",
       "      <td>730.666667</td>\n",
       "      <td>115.583333</td>\n",
       "      <td>92.083333</td>\n",
       "      <td>0.612994</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>7.029167</td>\n",
       "      <td>7.735417</td>\n",
       "      <td>9.369167</td>\n",
       "      <td>6.840417</td>\n",
       "      <td>7.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.5</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>239.416667</td>\n",
       "      <td>956.791667</td>\n",
       "      <td>141.666667</td>\n",
       "      <td>109.958333</td>\n",
       "      <td>0.583796</td>\n",
       "      <td>49.166667</td>\n",
       "      <td>9.579167</td>\n",
       "      <td>8.289167</td>\n",
       "      <td>11.692917</td>\n",
       "      <td>8.684167</td>\n",
       "      <td>11.437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Word Count  Syllable Count  Character Count  Complex Word Count  \\\n",
       "label                                                                           \n",
       "0       11.5   55.500000       57.541667       243.166667           42.833333   \n",
       "1       35.5   76.000000       89.333333       361.458333           51.375000   \n",
       "2       59.5  106.791667      118.833333       498.208333           80.750000   \n",
       "3       83.5  154.666667      183.416667       730.666667          115.583333   \n",
       "4      107.5  191.000000      239.416667       956.791667          141.666667   \n",
       "\n",
       "       Vocab Size  Lexical Diversity  Noun Chunks  Flesch Kincaid Score  \\\n",
       "label                                                                     \n",
       "0       37.958333           0.687275    15.541667              2.900000   \n",
       "1       51.458333           0.685836    20.291667              7.591667   \n",
       "2       70.208333           0.658725    29.250000              5.229167   \n",
       "3       92.083333           0.612994    40.500000              7.029167   \n",
       "4      109.958333           0.583796    49.166667              9.579167   \n",
       "\n",
       "       Dale Chall Score  Gunning Fog Index  Coleman Liau Index  \\\n",
       "label                                                            \n",
       "0              6.295417           4.695000            3.884583   \n",
       "1              8.812917           9.763750            7.345000   \n",
       "2              7.376667           7.239583            6.082083   \n",
       "3              7.735417           9.369167            6.840417   \n",
       "4              8.289167          11.692917            8.684167   \n",
       "\n",
       "       Automated Readability Index  \n",
       "label                               \n",
       "0                         3.229167  \n",
       "1                         8.570833  \n",
       "2                         6.262500  \n",
       "3                         7.616667  \n",
       "4                        11.437500  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_wrong_stats = bert_features.groupby('label').agg('mean')\n",
    "bert_wrong_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6ef1dd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable Count</th>\n",
       "      <th>Character Count</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Vocab Size</th>\n",
       "      <th>Lexical Diversity</th>\n",
       "      <th>Noun Chunks</th>\n",
       "      <th>Flesch Kincaid Score</th>\n",
       "      <th>Dale Chall Score</th>\n",
       "      <th>Gunning Fog Index</th>\n",
       "      <th>Coleman Liau Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.708333</td>\n",
       "      <td>11.291667</td>\n",
       "      <td>50.291667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>1.691667</td>\n",
       "      <td>1.963333</td>\n",
       "      <td>2.010833</td>\n",
       "      <td>1.455833</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>-4.041667</td>\n",
       "      <td>-10.708333</td>\n",
       "      <td>7.041667</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>-2.683333</td>\n",
       "      <td>-1.402917</td>\n",
       "      <td>-3.250833</td>\n",
       "      <td>-2.150417</td>\n",
       "      <td>-3.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>140.125000</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>-0.005603</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>2.912500</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>3.013333</td>\n",
       "      <td>1.265417</td>\n",
       "      <td>3.095833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>79.708333</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>-0.027894</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>1.229167</td>\n",
       "      <td>-0.191250</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>0.649583</td>\n",
       "      <td>1.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.875000</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>-41.166667</td>\n",
       "      <td>-2.583333</td>\n",
       "      <td>-1.208333</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>-1.541667</td>\n",
       "      <td>-0.359583</td>\n",
       "      <td>-1.586250</td>\n",
       "      <td>-0.562917</td>\n",
       "      <td>-2.275000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Word Count  Syllable Count  Character Count  Complex Word Count  \\\n",
       "label                                                                           \n",
       "0        0.0   11.708333       11.291667        50.291667            3.833333   \n",
       "1        0.0    2.041667       -4.041667       -10.708333            7.041667   \n",
       "2        0.0   25.666667       39.500000       140.125000           18.083333   \n",
       "3        0.0    9.500000       20.166667        79.708333           10.750000   \n",
       "4        0.0   -5.875000       -9.500000       -41.166667           -2.583333   \n",
       "\n",
       "       Vocab Size  Lexical Diversity  Noun Chunks  Flesch Kincaid Score  \\\n",
       "label                                                                     \n",
       "0        9.333333           0.023721     2.875000              1.691667   \n",
       "1        1.458333           0.002921     1.708333             -2.683333   \n",
       "2       15.625000          -0.005603     4.375000              2.912500   \n",
       "3        3.250000          -0.027894     4.541667              1.229167   \n",
       "4       -1.208333           0.008194    -1.833333             -1.541667   \n",
       "\n",
       "       Dale Chall Score  Gunning Fog Index  Coleman Liau Index  \\\n",
       "label                                                            \n",
       "0              1.963333           2.010833            1.455833   \n",
       "1             -1.402917          -3.250833           -2.150417   \n",
       "2              0.725000           3.013333            1.265417   \n",
       "3             -0.191250           0.884167            0.649583   \n",
       "4             -0.359583          -1.586250           -0.562917   \n",
       "\n",
       "       Automated Readability Index  \n",
       "label                               \n",
       "0                         2.375000  \n",
       "1                        -3.437500  \n",
       "2                         3.095833  \n",
       "3                         1.675000  \n",
       "4                        -2.275000  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob_wrong_stats - bert_wrong_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b954c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
